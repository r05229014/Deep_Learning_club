{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "\n",
    "# use gpu\n",
    "cuda = True\n",
    "cuda = cuda and torch.cuda.is_available()\n",
    "\n",
    "seed = 666\n",
    "if cuda:\n",
    "    torch.cuda.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load MNIST data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('./data'):\n",
    "    os.mkdir('./data')\n",
    "    \n",
    "trans = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (1.0,))])\n",
    "train_set = dset.MNIST(root='./data', train=True, transform=trans, download=False)\n",
    "test_set = dset.MNIST(root='./data', train=False, transform=trans, download=False)\n",
    "\n",
    "batch_size = 64\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "                 dataset=train_set,\n",
    "                 batch_size=batch_size,\n",
    "                 shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "                dataset=test_set,\n",
    "                batch_size=batch_size,\n",
    "                shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch = next(iter(test_loader)) # test loader is an iterable\n",
    "samples = batch[0][:5]\n",
    "y_true = batch[1]\n",
    "for i, sample in enumerate(samples):\n",
    "    plt.subplot(1, 5, i+1)\n",
    "    plt.title('Number: %i' %y_true[i])\n",
    "    plt.imshow(sample.numpy().reshape(28,28))\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NN, self).__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(28*28, 256)\n",
    "        self.fc2 = nn.Linear(256, 256)\n",
    "        self.fc3 = nn.Linear(256,10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28*28)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        out = F.softmax(self.fc3(x))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ericakcc/anaconda3/envs/pytorch/lib/python3.6/site-packages/ipykernel_launcher.py:13: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Train Epoch: 0 [64/60000 (0%)]\tLoss: 2.301097\n",
      " Train Epoch: 0 [6464/60000 (11%)]\tLoss: 1.619173\n",
      " Train Epoch: 0 [12864/60000 (21%)]\tLoss: 1.605539\n",
      " Train Epoch: 0 [19264/60000 (32%)]\tLoss: 1.585468\n",
      " Train Epoch: 0 [25664/60000 (43%)]\tLoss: 1.581948\n",
      " Train Epoch: 0 [32064/60000 (53%)]\tLoss: 1.550701\n",
      " Train Epoch: 0 [38464/60000 (64%)]\tLoss: 1.538856\n",
      " Train Epoch: 0 [44864/60000 (75%)]\tLoss: 1.530743\n",
      " Train Epoch: 0 [51264/60000 (85%)]\tLoss: 1.533216\n",
      " Train Epoch: 0 [57664/60000 (96%)]\tLoss: 1.557186\n",
      " Train Epoch: 1 [64/60000 (0%)]\tLoss: 1.569079\n",
      " Train Epoch: 1 [6464/60000 (11%)]\tLoss: 1.558888\n",
      " Train Epoch: 1 [12864/60000 (21%)]\tLoss: 1.598992\n",
      " Train Epoch: 1 [19264/60000 (32%)]\tLoss: 1.526896\n",
      " Train Epoch: 1 [25664/60000 (43%)]\tLoss: 1.531517\n",
      " Train Epoch: 1 [32064/60000 (53%)]\tLoss: 1.547326\n",
      " Train Epoch: 1 [38464/60000 (64%)]\tLoss: 1.533538\n",
      " Train Epoch: 1 [44864/60000 (75%)]\tLoss: 1.590641\n",
      " Train Epoch: 1 [51264/60000 (85%)]\tLoss: 1.470651\n",
      " Train Epoch: 1 [57664/60000 (96%)]\tLoss: 1.602085\n",
      " Train Epoch: 2 [64/60000 (0%)]\tLoss: 1.543755\n",
      " Train Epoch: 2 [6464/60000 (11%)]\tLoss: 1.506886\n",
      " Train Epoch: 2 [12864/60000 (21%)]\tLoss: 1.492985\n",
      " Train Epoch: 2 [19264/60000 (32%)]\tLoss: 1.488934\n",
      " Train Epoch: 2 [25664/60000 (43%)]\tLoss: 1.491505\n",
      " Train Epoch: 2 [32064/60000 (53%)]\tLoss: 1.504260\n",
      " Train Epoch: 2 [38464/60000 (64%)]\tLoss: 1.499109\n",
      " Train Epoch: 2 [44864/60000 (75%)]\tLoss: 1.534349\n",
      " Train Epoch: 2 [51264/60000 (85%)]\tLoss: 1.501395\n",
      " Train Epoch: 2 [57664/60000 (96%)]\tLoss: 1.525301\n",
      " Train Epoch: 3 [64/60000 (0%)]\tLoss: 1.511479\n",
      " Train Epoch: 3 [6464/60000 (11%)]\tLoss: 1.506761\n",
      " Train Epoch: 3 [12864/60000 (21%)]\tLoss: 1.557392\n",
      " Train Epoch: 3 [19264/60000 (32%)]\tLoss: 1.534579\n",
      " Train Epoch: 3 [25664/60000 (43%)]\tLoss: 1.551345\n",
      " Train Epoch: 3 [32064/60000 (53%)]\tLoss: 1.509088\n",
      " Train Epoch: 3 [38464/60000 (64%)]\tLoss: 1.526233\n",
      " Train Epoch: 3 [44864/60000 (75%)]\tLoss: 1.499915\n",
      " Train Epoch: 3 [51264/60000 (85%)]\tLoss: 1.533748\n",
      " Train Epoch: 3 [57664/60000 (96%)]\tLoss: 1.477627\n",
      " Train Epoch: 4 [64/60000 (0%)]\tLoss: 1.510493\n",
      " Train Epoch: 4 [6464/60000 (11%)]\tLoss: 1.469017\n",
      " Train Epoch: 4 [12864/60000 (21%)]\tLoss: 1.509364\n",
      " Train Epoch: 4 [19264/60000 (32%)]\tLoss: 1.508803\n",
      " Train Epoch: 4 [25664/60000 (43%)]\tLoss: 1.467407\n",
      " Train Epoch: 4 [32064/60000 (53%)]\tLoss: 1.498372\n",
      " Train Epoch: 4 [38464/60000 (64%)]\tLoss: 1.494393\n",
      " Train Epoch: 4 [44864/60000 (75%)]\tLoss: 1.479008\n",
      " Train Epoch: 4 [51264/60000 (85%)]\tLoss: 1.467198\n",
      " Train Epoch: 4 [57664/60000 (96%)]\tLoss: 1.525236\n",
      " Train Epoch: 5 [64/60000 (0%)]\tLoss: 1.479389\n",
      " Train Epoch: 5 [6464/60000 (11%)]\tLoss: 1.476523\n",
      " Train Epoch: 5 [12864/60000 (21%)]\tLoss: 1.476993\n",
      " Train Epoch: 5 [19264/60000 (32%)]\tLoss: 1.503296\n",
      " Train Epoch: 5 [25664/60000 (43%)]\tLoss: 1.498039\n",
      " Train Epoch: 5 [32064/60000 (53%)]\tLoss: 1.498022\n",
      " Train Epoch: 5 [38464/60000 (64%)]\tLoss: 1.461839\n",
      " Train Epoch: 5 [44864/60000 (75%)]\tLoss: 1.502602\n",
      " Train Epoch: 5 [51264/60000 (85%)]\tLoss: 1.477171\n",
      " Train Epoch: 5 [57664/60000 (96%)]\tLoss: 1.548958\n",
      " Train Epoch: 6 [64/60000 (0%)]\tLoss: 1.523017\n",
      " Train Epoch: 6 [6464/60000 (11%)]\tLoss: 1.462330\n",
      " Train Epoch: 6 [12864/60000 (21%)]\tLoss: 1.489900\n",
      " Train Epoch: 6 [19264/60000 (32%)]\tLoss: 1.474744\n",
      " Train Epoch: 6 [25664/60000 (43%)]\tLoss: 1.490912\n",
      " Train Epoch: 6 [32064/60000 (53%)]\tLoss: 1.525784\n",
      " Train Epoch: 6 [38464/60000 (64%)]\tLoss: 1.487170\n",
      " Train Epoch: 6 [44864/60000 (75%)]\tLoss: 1.539567\n",
      " Train Epoch: 6 [51264/60000 (85%)]\tLoss: 1.505322\n",
      " Train Epoch: 6 [57664/60000 (96%)]\tLoss: 1.507204\n",
      " Train Epoch: 7 [64/60000 (0%)]\tLoss: 1.484767\n",
      " Train Epoch: 7 [6464/60000 (11%)]\tLoss: 1.476849\n",
      " Train Epoch: 7 [12864/60000 (21%)]\tLoss: 1.480187\n",
      " Train Epoch: 7 [19264/60000 (32%)]\tLoss: 1.508619\n",
      " Train Epoch: 7 [25664/60000 (43%)]\tLoss: 1.492915\n",
      " Train Epoch: 7 [32064/60000 (53%)]\tLoss: 1.476831\n",
      " Train Epoch: 7 [38464/60000 (64%)]\tLoss: 1.483864\n",
      " Train Epoch: 7 [44864/60000 (75%)]\tLoss: 1.461338\n",
      " Train Epoch: 7 [51264/60000 (85%)]\tLoss: 1.517919\n",
      " Train Epoch: 7 [57664/60000 (96%)]\tLoss: 1.492401\n",
      " Train Epoch: 8 [64/60000 (0%)]\tLoss: 1.477388\n",
      " Train Epoch: 8 [6464/60000 (11%)]\tLoss: 1.515074\n",
      " Train Epoch: 8 [12864/60000 (21%)]\tLoss: 1.503215\n",
      " Train Epoch: 8 [19264/60000 (32%)]\tLoss: 1.522915\n",
      " Train Epoch: 8 [25664/60000 (43%)]\tLoss: 1.521345\n",
      " Train Epoch: 8 [32064/60000 (53%)]\tLoss: 1.507281\n",
      " Train Epoch: 8 [38464/60000 (64%)]\tLoss: 1.539223\n",
      " Train Epoch: 8 [44864/60000 (75%)]\tLoss: 1.474533\n",
      " Train Epoch: 8 [51264/60000 (85%)]\tLoss: 1.461545\n",
      " Train Epoch: 8 [57664/60000 (96%)]\tLoss: 1.493824\n",
      " Train Epoch: 9 [64/60000 (0%)]\tLoss: 1.488330\n",
      " Train Epoch: 9 [6464/60000 (11%)]\tLoss: 1.461177\n",
      " Train Epoch: 9 [12864/60000 (21%)]\tLoss: 1.521018\n",
      " Train Epoch: 9 [19264/60000 (32%)]\tLoss: 1.461151\n",
      " Train Epoch: 9 [25664/60000 (43%)]\tLoss: 1.461157\n",
      " Train Epoch: 9 [32064/60000 (53%)]\tLoss: 1.479636\n",
      " Train Epoch: 9 [38464/60000 (64%)]\tLoss: 1.520493\n",
      " Train Epoch: 9 [44864/60000 (75%)]\tLoss: 1.461151\n",
      " Train Epoch: 9 [51264/60000 (85%)]\tLoss: 1.492587\n",
      " Train Epoch: 9 [57664/60000 (96%)]\tLoss: 1.475020\n"
     ]
    }
   ],
   "source": [
    "model = NN()\n",
    "if cuda:\n",
    "    model.cuda()\n",
    "model.train()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)  # opt\n",
    "\n",
    "losses = []\n",
    "for epoch in range(10):\n",
    "    # training\n",
    "    for i, (batch_x, batch_y) in enumerate(train_loader):\n",
    "        # get input \n",
    "        X, y = Variable(batch_x.cuda()), Variable(batch_y.cuda())\n",
    "        optimizer.zero_grad()  # zero the gradient buffers\n",
    "        \n",
    "        # Predict by model\n",
    "        out = model(X)\n",
    "        \n",
    "        # Calculate loss \n",
    "        loss = F.cross_entropy(out, y)\n",
    "        losses.append(loss.item())\n",
    "        \n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()  # Does the update \n",
    "        \n",
    "        # Display \n",
    "        if i % 100 == 1:\n",
    "            print('\\r Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, \n",
    "                i * len(batch_x), \n",
    "                len(train_loader.dataset),\n",
    "                100. * i / len(train_loader), \n",
    "                loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f0060112780>]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot losses in every step\n",
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: tensor(0.9378)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ericakcc/.local/lib/python3.6/site-packages/torchvision/datasets/mnist.py:58: UserWarning: test_data has been renamed data\n",
      "  warnings.warn(\"test_data has been renamed data\")\n",
      "/home/ericakcc/.local/lib/python3.6/site-packages/torchvision/datasets/mnist.py:48: UserWarning: test_labels has been renamed targets\n",
      "  warnings.warn(\"test_labels has been renamed targets\")\n",
      "/home/ericakcc/anaconda3/envs/pytorch/lib/python3.6/site-packages/ipykernel_launcher.py:13: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "evaluate_x = Variable(test_loader.dataset.test_data.type_as(torch.FloatTensor())).cuda()\n",
    "evaluate_y = Variable(test_loader.dataset.test_labels).cuda()\n",
    "\n",
    "\n",
    "output = model(evaluate_x)\n",
    "pred = output.data.max(1)[1]\n",
    "d = pred.eq(evaluate_y.data).cpu()\n",
    "accuracy = d.sum().float()/d.size()[0]\n",
    "\n",
    "print('Accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN  3/27"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels =1, out_channels=16, kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "        \n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(16,32,5,1,2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        self.out = nn.Linear(32*7*7,10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = x.view(x.size(0),-1)  # in keras this is flatten()\n",
    "        output = self.out(x)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (conv1): Sequential(\n",
      "    (0): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv2): Sequential(\n",
      "    (0): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (out): Linear(in_features=1568, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = CNN()\n",
    "print(cnn)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)  # opt\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()\n",
    "    criterion = criterion.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    print('Training......')\n",
    "    model.train()\n",
    "\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = Variable(data), Variable(target)\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            data = data.cuda()\n",
    "            target = target.cuda()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (batch_idx + 1)% 100 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, (batch_idx + 1) * len(data), len(train_loader.dataset),\n",
    "                100. * (batch_idx + 1) / len(train_loader), loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(data_loader):\n",
    "    model.eval()\n",
    "    loss = 0\n",
    "    correct = 0\n",
    "    \n",
    "    for data, target in data_loader:\n",
    "        data, target = Variable(data, volatile=True), Variable(target)\n",
    "        if torch.cuda.is_available():\n",
    "            data = data.cuda()\n",
    "            target = target.cuda()\n",
    "        \n",
    "        output = model(data)\n",
    "        \n",
    "        loss += F.cross_entropy(output, target, size_average=False).item()\n",
    "\n",
    "        pred = output.data.max(1, keepdim=True)[1]\n",
    "        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "        \n",
    "    loss /= len(data_loader.dataset)\n",
    "        \n",
    "    print('\\nAverage loss: {:.4f}, Accuracy: {}/{} ({:.3f}%)\\n'.format(\n",
    "        loss, correct, len(data_loader.dataset),\n",
    "        100. * correct / len(data_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training......\n",
      "Train Epoch: 0 [6400/60000 (11%)]\tLoss: 0.050945\n",
      "Train Epoch: 0 [12800/60000 (21%)]\tLoss: 0.064526\n",
      "Train Epoch: 0 [19200/60000 (32%)]\tLoss: 0.040814\n",
      "Train Epoch: 0 [25600/60000 (43%)]\tLoss: 0.064009\n",
      "Train Epoch: 0 [32000/60000 (53%)]\tLoss: 0.007286\n",
      "Train Epoch: 0 [38400/60000 (64%)]\tLoss: 0.062923\n",
      "Train Epoch: 0 [44800/60000 (75%)]\tLoss: 0.143851\n",
      "Train Epoch: 0 [51200/60000 (85%)]\tLoss: 0.016554\n",
      "Train Epoch: 0 [57600/60000 (96%)]\tLoss: 0.014034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ericakcc/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:7: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  import sys\n",
      "/home/ericakcc/.local/lib/python3.6/site-packages/torch/nn/_reduction.py:49: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average loss: 0.0389, Accuracy: 59321/60000 (98.000%)\n",
      "\n",
      "Training......\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.115316\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.089290\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.042864\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.017153\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.027199\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.032549\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.020235\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.009436\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.027288\n",
      "\n",
      "Average loss: 0.0326, Accuracy: 59399/60000 (98.000%)\n",
      "\n",
      "Training......\n",
      "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.022684\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.029744\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.007821\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.020615\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.004520\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.001376\n",
      "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.038656\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.013938\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.071141\n",
      "\n",
      "Average loss: 0.0237, Accuracy: 59548/60000 (99.000%)\n",
      "\n",
      "Training......\n",
      "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.026245\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.003002\n",
      "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.007898\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.032008\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.002597\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.014082\n",
      "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.025539\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.010775\n",
      "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.007164\n",
      "\n",
      "Average loss: 0.0182, Accuracy: 59666/60000 (99.000%)\n",
      "\n",
      "Training......\n",
      "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.001537\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.010979\n",
      "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.001446\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.110727\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.003013\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.002280\n",
      "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.072006\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.079749\n",
      "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.028957\n",
      "\n",
      "Average loss: 0.0169, Accuracy: 59685/60000 (99.000%)\n",
      "\n",
      "Training......\n",
      "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.002163\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.002451\n",
      "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.022920\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.027983\n",
      "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.055146\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.020750\n",
      "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.066318\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.013367\n",
      "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.013588\n",
      "\n",
      "Average loss: 0.0175, Accuracy: 59658/60000 (99.000%)\n",
      "\n",
      "Training......\n",
      "Train Epoch: 6 [6400/60000 (11%)]\tLoss: 0.004663\n",
      "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.001225\n",
      "Train Epoch: 6 [19200/60000 (32%)]\tLoss: 0.027315\n",
      "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 0.000983\n",
      "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 0.003228\n",
      "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.002105\n",
      "Train Epoch: 6 [44800/60000 (75%)]\tLoss: 0.003316\n",
      "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.001081\n",
      "Train Epoch: 6 [57600/60000 (96%)]\tLoss: 0.024563\n",
      "\n",
      "Average loss: 0.0099, Accuracy: 59814/60000 (99.000%)\n",
      "\n",
      "Training......\n",
      "Train Epoch: 7 [6400/60000 (11%)]\tLoss: 0.002913\n",
      "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.003615\n",
      "Train Epoch: 7 [19200/60000 (32%)]\tLoss: 0.001648\n",
      "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 0.002979\n",
      "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 0.062731\n",
      "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.022962\n",
      "Train Epoch: 7 [44800/60000 (75%)]\tLoss: 0.000195\n",
      "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.018339\n",
      "Train Epoch: 7 [57600/60000 (96%)]\tLoss: 0.065193\n",
      "\n",
      "Average loss: 0.0084, Accuracy: 59844/60000 (99.000%)\n",
      "\n",
      "Training......\n",
      "Train Epoch: 8 [6400/60000 (11%)]\tLoss: 0.000063\n",
      "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 0.002955\n",
      "Train Epoch: 8 [19200/60000 (32%)]\tLoss: 0.009431\n",
      "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.015843\n",
      "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 0.058971\n",
      "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.028872\n",
      "Train Epoch: 8 [44800/60000 (75%)]\tLoss: 0.000813\n",
      "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.000314\n",
      "Train Epoch: 8 [57600/60000 (96%)]\tLoss: 0.060342\n",
      "\n",
      "Average loss: 0.0091, Accuracy: 59825/60000 (99.000%)\n",
      "\n",
      "Training......\n",
      "Train Epoch: 9 [6400/60000 (11%)]\tLoss: 0.000865\n",
      "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 0.001332\n",
      "Train Epoch: 9 [19200/60000 (32%)]\tLoss: 0.001474\n",
      "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 0.023618\n",
      "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 0.003636\n",
      "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 0.001010\n",
      "Train Epoch: 9 [44800/60000 (75%)]\tLoss: 0.004944\n",
      "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.000204\n",
      "Train Epoch: 9 [57600/60000 (96%)]\tLoss: 0.000235\n",
      "\n",
      "Average loss: 0.0099, Accuracy: 59788/60000 (99.000%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 10\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    train(epoch)\n",
    "    evaluate(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
